---
title: "Part 2: Probability"
author: "Sam Tyner"
date: "TBD"
output: 
  beamer_presentation:
    theme: "AnnArbor"
    colortheme: "dolphin"
    includes:
      in_header: header.tex
      before_body: slide_prefix.tex
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.align = 'center', fig.width = 6)
```

```{r loadpkgs}
library(tidyverse)
```

## Textbook

These slides are based on the book *OpenIntro Statistics* by David Diez, Christopher Barr, and Mine Ã‡etinkaya-Rundel

The book can be downloaded from [https://www.openintro.org/stat/textbook.php](https://www.openintro.org/stat/textbook.php)

Part 2 Corresponds to Chapter 2 of the text. Sections 2.1-2.4 correspond to sections 2.1, 2.2, 2.4, 2.5 of the text.

## Outline 

- Defining Probability (2.1)
- Conditional probability (2.2)
- Random variables (2.3)
- Continuous distributions (2.4)

# Section 2.1: Defining Probability

## What is probability?

\begin{figure}
\centering
\includegraphics[width=.5\linewidth]{img/confused.png}
\caption{Confused Nick Young. What is probability???}
\end{figure}

## Very formal definition 

> The probability of an outcome is the proportion of times the outcome would occur if we observed the random process an infinite number of times.

- What is an outcome? 
- What is a random process? 

## Very formal definition 

> The probability of an outcome is the proportion of times the outcome would occur if we observed the random process an infinite number of times.

- What is an outcome? \textcolor{red}{Any event or outcome of interest}
- What is a random process?  \textcolor{red}{Anything that causes events at random that can theoretically happen an infinite number of times}

## Examples 

Random Process | Outcome 
:-------------:|:-------:
Roll of a die | 6
Flip of a coin | Heads 

Others? 

## Some notation

$P(A)$ - often used to denote the probability of event $A$

Probability is always between 0 and 1. In symbols: $0 \leq P(A) \leq 1$

Probability can also be expressed as a percentage: $100 \times P(A) \%$

- e.g. $P(A) = 0.45$ is equivalent to $45\%$, $P(A) = 0.015$ is equivalent to $1.5\%$

Example: 

- Suppose we are rolling a fair 6-sided die. There are 6 outcomes, $\{1,2,3,4,5,6\}$, and we are interested in the outcome $1$. 
- What is $P(1)$? 

## Law of Large Numbers (Activity)

>- Suppose we are rolling a fair 6-sided die. There are 6 outcomes, $\{1,2,3,4,5,6\}$, and we are interested in the outcome $1$. 
>- We roll the die $n$ times. The symbol $\hat{p}_n$ represents the proportion of observed outcomes that are $1$ after the first $n$ rolls.
>- As the number of rolls ($n$) increases, $\hat{p}_n$ (observed probability) will get closer and closer to the theoretical probability $p$.
>- For this example, $p = \frac{1}{6}$
>- This is due to the **Law of Large Numbers**: the tendency of observed probabilities to approach theoretical probabilities as the number of total observations increases. 

## Disjoint outcomes 

- Two outcomes are **disjoint** (also called **mutually exclusive**) if they cannot both happen 
- Example: In a single roll of a die, the outcome $1$ and the outcome $2$ are disjoint, because they cannot both happen. 
- Example: In a single roll of a die, the outcome $1$ and the outcome "rolling an odd number" are NOT disjoint because if you roll a $1$, both outcomes have happened. 

## Probability of disjoint outcomes 

- Let $A$ and $B$ denote 2 disjoint events. Their probabilities are denoted $P(A)$ and $P(B)$ 
- We are interested in the probability of either $A$ or $B$ occurring: denoted $P(A \text{ or } B)$. 
- To compute this probability, we use the **addition rule of disjoint outcomes**
$$P(A \text{ or } B) = P(A) + P(B)$$
- In words: if two outcomes are disjoint, the probability that one of the two will occur is the sum of their individual probabilities 
- Addition rule applies for more than 2 outcomes as well as long as ALL outcomes are **disjoint**.

## Probabilities when events are not disjoint
<!--latex below taken directly from os3 github page-->
Example: Standard deck of cards 

\begin{table}[h]
\centering
\begin{tabular}{lll lll lll lll l}
{2$\clubsuit$} & {3$\clubsuit$} & {4$\clubsuit$} & {5$\clubsuit$} & {6$\clubsuit$} & {7$\clubsuit$} & {8$\clubsuit$} & {9$\clubsuit$} & {10$\clubsuit$} & {J$\clubsuit$} & {Q$\clubsuit$} & {K$\clubsuit$} & {A$\clubsuit$}  \\
\color{red} {2$\diamondsuit$} & \color{red}{3$\diamondsuit$} & \color{red}{4$\diamondsuit$} & \color{red}{5$\diamondsuit$} & \color{red}{6$\diamondsuit$} & \color{red}{7$\diamondsuit$} & \color{red}{8$\diamondsuit$} & \color{red}{9$\diamondsuit$} & \color{red}{10$\diamondsuit$} & \color{red}{J$\diamondsuit$} & \color{red}{Q$\diamondsuit$} & \color{red}{K$\diamondsuit$} & \color{red}{A$\diamondsuit$} \\
\color{red}{2$\heartsuit$} & \color{red}{3$\heartsuit$} & \color{red}{4$\heartsuit$} & \color{red}{5$\heartsuit$} & \color{red}{6$\heartsuit$} & \color{red}{7$\heartsuit$} & \color{red}{8$\heartsuit$} & \color{red}{9$\heartsuit$} & \color{red}{10$\heartsuit$} & \color{red}{J$\heartsuit$} & \color{red}{Q$\heartsuit$} & \color{red}{K$\heartsuit$} & \color{red}{A$\heartsuit$} \\
{2$\spadesuit$} & {3$\spadesuit$} & {4$\spadesuit$} & {5$\spadesuit$} & {6$\spadesuit$} & {7$\spadesuit$} & {8$\spadesuit$} & {9$\spadesuit$} & {10$\spadesuit$} & {J$\spadesuit$} & {Q$\spadesuit$} & {K$\spadesuit$} & {A$\spadesuit$}
\end{tabular}
\caption{Representations of the 52 unique cards in a deck.}
\label{deckOfCards}
\end{table}

What are some non-disjoint events? 

## Non-disjoint examples 

When drawing a card at random from a deck of cards: 

- Let $A$ represent the outcome that the card is a diamond
- Let $B$ represent the outcome that the card is a face card
- What is the probability of $A$ or $B$? 

Question: why aren't these events disjoint? 

## Non-disjoint examples 

When drawing a card at random from a deck of cards: 

- Let $A$ represent the outcome that the card is a diamond
- Let $B$ represent the outcome that the card is a face card
- What is the probability of $A$ or $B$? 

Question: why aren't these events disjoint? Because \color{red}{J$\diamondsuit$}, \color{red}{Q$\diamondsuit$}, \color{red}{K$\diamondsuit$} are outcomes that fall into $A$ and $B$. 

## Probabilities when events are not disjoint (ex.)

If we used the addition rule, the outcomes \textcolor{red}{J$\diamondsuit$}, \textcolor{red}{Q$\diamondsuit$}, \textcolor{red}{K$\diamondsuit$} would be counted twice: once for outcome $A$, and once for outcome $B$.

\begin{align*}
P(A \text{ or } B) & = P( \textcolor{red}{\diamondsuit} \text{ or face card}) \\
  & = P(\textcolor{red}{\diamondsuit}) + P(\text{face card}) - P(\textcolor{red}{\diamondsuit} \text{ AND face card}) \\
  & = \frac{13}{52} + \frac{12}{52} - \frac{3}{52} \\ 
  & = \frac{22}{52} = \frac{11}{26} \approx 0.4231 \equiv 42.31\%
\end{align*}

## General Addition Rule 

If $A$ and $B$ are any two events, disjoint or not, then the probability that at least one of them will occur is 

$$P(A \text{ or } B) = P(A) + P(B) - P(A \text{ and } B)$$
where $P(A \text{ and } B)$ is the probability that both events occur.

Note: If $A$ and $B$ are disjoint, what does $P(A \text{ and } B)$ equal? 

## Probability distributions 

A (discrete) **probability distribution** is a table of all disjoint outcomes and their associated probabilities. 

Example: consider the sum of a roll of two 6-sided dice.

$\frac{\text{Roll } 1 \rightarrow}{\text{Roll } 2 \quad \downarrow}$|1 | 2 | 3 | 4 | 5 | 6 
-|--|---|---|---|---|---
1|2 |3  | 4 | 5 | 6 | 7
2|3 |4  | 5 | 6 | 7 | 8
3|4 |5  | 6 | 7 | 8 | 9
4|5 |6  | 7 | 8 | 9 | 10
5|6 |7  | 8 | 9 | 10 | 11
6|7 |8  | 9 | 10 | 11| 12

Sum         | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12
:-----------|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:--:|:--:|:--:
Probability | $\frac{1}{36}$ | $\frac{2}{36}$ |$\frac{3}{36}$ |$\frac{4}{36}$ |$\frac{5}{36}$ |$\frac{6}{36}$ |$\frac{5}{36}$ |$\frac{4}{36}$ |$\frac{3}{36}$ |$\frac{2}{36}$ |$\frac{1}{36}$ 

## Probability Distributions 

A probability distribution is a list of the possible outcomes of a random process with corresponding probabilities that satisfies three rules:

1. The outcomes listed must be disjoint.
2. Each probability must be between 0 and 1. 
3. The probabilities must total 1.

```{r probdist, fig.height = 3, out.width=".49\\linewidth", fig.show='hold'}
roll <- data.frame(x = 2:12, prob = c(1:6, 5:1)/36, cumprob = cumsum(c(1:6, 5:1)/36))

ggplot(data = roll) + 
  geom_bar(aes(x = as.factor(x), weight = prob)) + 
  labs(x = "Sum of 2 dice", y = "Probability") + 
  theme(text = element_text(size = rel(4)))
ggplot(data = roll) + 
  geom_bar(aes(x = as.factor(x), weight = cumprob)) + 
  labs(x = "Sum of 2 dice", y = "Cumulative Probability") + 
  theme(text = element_text(size = rel(4)))
```

## Complement of an Event

- The **sample space** ($\mathcal{S}$) is a list of all possible outcomes of a random process 
- For an event $A$, the **complement** of $A$, denoted $A^c$ is the set of all outcomes in the sample space that are not in $A$.
- For example, for a 6-sided die, $\mathcal{S} = \{1,2,3,4,5,6\}$
- Let $A = \{2,3\}$ be the event that the outcome of a die roll is $2$ or $3$. 
- The complement of $A$ is $A^c = \{1,4,5,6\}$

## Complement of an Event 

- $A$ and $A^c$ are **disjoint** by definition
- $P(A \text{ or } A^c) = 1$
- $P(A \text{ or } A^c) = P(A) + P(A^c)= 1$
- $P(A^c) = 1 - P(A)$ 

## Independence 

- Two random processes are **independent** if knowing the outcome of one doesn't inform the outcome of the other. 
- Example: the processes "rolling a die" and "flipping a coin" are independent 
- Example: rolling 2 dice
- Suppose one die is red and the other is white. We roll the red die, then the white die. What is the probability that they will both be $1$? 

## Independence 

- Two random processes are **independent** if knowing the outcome of one doesn't inform the outcome of the other. 
- Example: the processes "rolling a die" and "flipping a coin" are independent 
- Example: rolling 2 dice
- Suppose one die is red and the other is white. We roll the red die, then the white die. What is the probability that they will both be $1$?
- \textcolor{red}{$P(\text{white } =1 \text{ and red }=1)= \frac{1}{6} \times \frac{1}{6} = \frac{1}{36}$}

## Multiplication Rule for independent processes


If $A$ and $B$ represent events from two different and independent processes, then the probability that both $A$ and $B$ occur can be calculated as the product of their separate probabilities:
$$P(A \text{ and } B) = P(A) \times P(B)$$

- This is also true for more than 2 independent events, as long as they are ALL independent.
- This is also used as a definition to determine if two events are independent. i.e. if we know $P(A)$, $P(B)$, and $P(A \text{ and } B)$, we can figure out if the events are independent. 

# Section 2.2: Conditional probability

## Example 

Recall the Your Turn 1.7.2 from Part 1. Is the probability of supporting the DREAM act the same for conservatives as it is for liberals? Why? 

```{r dream, fig.height=3, fig.width=3}
dream <- openintro::dream
names(dream)[2] <- "support"
mosaicplot(~ ideology + support, data = dream, color = TRUE)
```

## Idea

**Conditional probablility** refers to a probability of an event when we already know that another event has occurred. 

- Example: Suppose we know the ideology (conservative, liberal, or moderate) of a randomly selected voter in the US. Does knowing that information change your guess about their support for the DREAM act? 

We'll get to a more formal definition of conditional probability after some preliminaries.

## Marginal Probability 

Here is the raw data for the DREAM act plot: 

```{r dreamdat, results='asis'}
tab <- data.frame(table(dream$support, dream$ideology))
tab <- spread(tab, Var2, Freq)
names(tab)[1] <- "Support"
tab <- mutate(tab, Total = Conservative + Liberal + Moderate) 
tab <- tab %>% add_row(Support = "Total", Conservative = sum(tab$Conservative), Liberal = sum(tab$Liberal), Moderate = sum(tab$Moderate), Total = sum(tab$Total))
knitr::kable(tab, caption = "Support by ideology for the DREAM act")
```

The **marginal probabilies** are the probabilities based on a single variable without regard to any other variables. (Here, row and column totals.) For example: $P(\text{support }= \text{ yes}) = \frac{474}{910} \approx 0.52$

## Joint probability 

A probability of outcomes for two or more variables or processes is called a **joint probability**. 

Example: $P(\text{support }= \text{ yes} \text{ and } \text{ideology }= \text{ conservative}) = \frac{186}{910} = 0.20$

## Defining conditional probability

# Section 2.3: Random variables

# Section 2.4: Continuous distributions